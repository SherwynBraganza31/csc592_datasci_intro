{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the initail copy of code from Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = \" \".join(\n",
    "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "\n",
    "# x corresponds to the data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y corresponds to the labells\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Change the model to use one hidden (aka \"representation\") layer, and see how this affects validation and test accuracy.  Show this by plotting them (on the same plot, like in the book).  Repeat this for three hidden layers.  Comment on any differences you find, as well as what you'd expect.\n",
    "\n",
    "\n",
    "**Part 1 - One Layer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "history_dict_onelayer = history.history\n",
    "history_dict_onelayer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Results of Model with One Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training Loss vs Validatin Loss \n",
    "loss_values = history_dict_onelayer[\"loss\"]\n",
    "val_loss_values = history_dict_onelayer[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, label=\"Training loss\", color = 'red', linestyle='--', marker = '^')\n",
    "plt.plot(epochs, val_loss_values, label=\"Validation loss\", color = 'green', linestyle='--', marker = '^')\n",
    "plt.title(\"One Hidden Layer Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Training Accuracy vs. Validation Accuracy\n",
    "acc = history_dict_onelayer[\"accuracy\"]\n",
    "val_acc = history_dict_onelayer[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, label=\"Training acc\", color='red', linestyle='--', marker='o')\n",
    "plt.plot(epochs, val_acc, label=\"Validation acc\", color='green', linestyle='--', marker='o')\n",
    "plt.title(\"One Hidden Layer Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - 3 Layer Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "history_dict_threelayers = history.history\n",
    "history_dict_threelayers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training Loss vs Validatin Loss \n",
    "loss_values = history_dict_threelayers[\"loss\"]\n",
    "val_loss_values = history_dict_threelayers[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, label=\"Training loss\", color = 'red', linestyle='--', marker = '^')\n",
    "plt.plot(epochs, val_loss_values, label=\"Validation loss\", color = 'green', linestyle='--', marker = '^')\n",
    "plt.title(\"One Hidden Layer Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Training Accuracy vs. Validation Accuracy\n",
    "acc = history_dict_threelayers[\"accuracy\"]\n",
    "val_acc = history_dict_threelayers[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, label=\"Training acc\", color='red', linestyle='--', marker='o')\n",
    "plt.plot(epochs, val_acc, label=\"Validation acc\", color='green', linestyle='--', marker='o')\n",
    "plt.title(\"One Hidden Layer Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Layer vs 3 Layer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = [\n",
    "    history_dict_onelayer['loss'],\n",
    "    history_dict_onelayer['val_loss'],\n",
    "    history_dict_threelayers['loss'],\n",
    "    history_dict_threelayers['val_loss']\n",
    "]\n",
    "\n",
    "acc_values = [\n",
    "    history_dict_onelayer['accuracy'],\n",
    "    history_dict_onelayer['val_accuracy'],\n",
    "    history_dict_threelayers['accuracy'],\n",
    "    history_dict_threelayers['val_accuracy']\n",
    "]\n",
    "\n",
    "loss_labels = ['One Layer ', 'Three Layer ', 'Training Loss', 'Validation Loss']\n",
    "accuracy_labels = ['One Layer ', 'Three Layer ', 'Training Accuracy', 'Validation Accuracy']\n",
    "colors = ['red', 'green', 'blue', 'magenta']\n",
    "\n",
    "for idx, x in enumerate(loss_values):\n",
    "    plt.plot(epochs, x, label=loss_labels[int(idx/2)] + loss_labels[idx%2 + 2], \n",
    "             color=colors[idx], linestyle='--', marker = '^')\n",
    "    \n",
    "plt.title(\"One Layer vs. Three Layer Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "for idx, x in enumerate(acc_values):\n",
    "    plt.plot(epochs, x, label=accuracy_labels[int(idx/2)] + accuracy_labels[idx%2 + 2], \n",
    "             color=colors[idx], linestyle='--', marker = 'o')\n",
    "    \n",
    "plt.title(\"One Layer vs. Three Layer Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best validation accuracy achieved was 89.09 by the 3 layer model. The best validation accuracy by the one layer model was 88.99\n",
    "\n",
    "On comparing the loss and accuracies of the one layer and three layer side by side, we can see that the validation accuracy changes for the worse after the 4th epoch. Conversely, the accuracy and loss corresponding to the training set steadily increases past the 4th epoch - this implies that the model is overfitting itself to the training data - and from this we can infer that the best model is achieved soon after the 4th epoch of training.\n",
    "\n",
    "<br>\n",
    "\n",
    "Another key feature to note is that both models have relatively similar loss and accuracy on the Validation Set uptill the 4th epoch, but the Three Layer model exhibits a higher training accuracy and lower loss than the one layer model; thereby telling us that the Three Layer Model performs slightly better.\n",
    "\n",
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Try changing the number of nodes in the hidden layers to 100.  See how this affects validation and test accuracy.  Show this by plotting them (on the same plot, like in the book).**\n",
    "\n",
    "#### Part 1 - 1 Layer, 100 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model Generation\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "history_dict_onelayer = history.history\n",
    "history_dict_onelayer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss vs Validatin Loss \n",
    "loss_values = history_dict_onelayer[\"loss\"]\n",
    "val_loss_values = history_dict_onelayer[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, label=\"Training loss\", color = 'red', linestyle='--', marker = '^')\n",
    "plt.plot(epochs, val_loss_values, label=\"Validation loss\", color = 'green', linestyle='--', marker = '^')\n",
    "plt.title(\"One Hidden Layer Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Training Accuracy vs. Validation Accuracy\n",
    "acc = history_dict_onelayer[\"accuracy\"]\n",
    "val_acc = history_dict_onelayer[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, label=\"Training acc\", color='red', linestyle='--', marker='o')\n",
    "plt.plot(epochs, val_acc, label=\"Validation acc\", color='green', linestyle='--', marker='o')\n",
    "plt.title(\"One Hidden Layer Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Three Layers, 100 Nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "history_dict_threelayers = history.history\n",
    "history_dict_threelayers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loss vs Validatin Loss \n",
    "loss_values = history_dict_threelayers[\"loss\"]\n",
    "val_loss_values = history_dict_threelayers[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, label=\"Training loss\", color = 'red', linestyle='--', marker = '^')\n",
    "plt.plot(epochs, val_loss_values, label=\"Validation loss\", color = 'green', linestyle='--', marker = '^')\n",
    "plt.title(\"One Hidden Layer Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Training Accuracy vs. Validation Accuracy\n",
    "acc = history_dict_threelayers[\"accuracy\"]\n",
    "val_acc = history_dict_threelayers[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, label=\"Training acc\", color='red', linestyle='--', marker='o')\n",
    "plt.plot(epochs, val_acc, label=\"Validation acc\", color='green', linestyle='--', marker='o')\n",
    "plt.title(\"One Hidden Layer Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Results from Part 1 and Part 2 Plotted Against each other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = [\n",
    "    history_dict_onelayer['loss'],\n",
    "    history_dict_onelayer['val_loss'],\n",
    "    history_dict_threelayers['loss'],\n",
    "    history_dict_threelayers['val_loss']\n",
    "]\n",
    "\n",
    "acc_values = [\n",
    "    history_dict_onelayer['accuracy'],\n",
    "    history_dict_onelayer['val_accuracy'],\n",
    "    history_dict_threelayers['accuracy'],\n",
    "    history_dict_threelayers['val_accuracy']\n",
    "]\n",
    "\n",
    "loss_labels = ['One Layer ', 'Three Layer ', 'Training Loss', 'Validation Loss']\n",
    "accuracy_labels = ['One Layer ', 'Three Layer ', 'Training Accuracy', 'Validation Accuracy']\n",
    "colors = ['red', 'green', 'blue', 'magenta']\n",
    "\n",
    "for idx, x in enumerate(loss_values):\n",
    "    plt.plot(epochs, x, label=loss_labels[int(idx/2)] + loss_labels[idx%2 + 2], \n",
    "             color=colors[idx], linestyle='--', marker = '^')\n",
    "    \n",
    "plt.title(\"One Layer vs. Three Layer Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "for idx, x in enumerate(acc_values):\n",
    "    plt.plot(epochs, x, label=accuracy_labels[int(idx/2)] + accuracy_labels[idx%2 + 2], \n",
    "             color=colors[idx], linestyle='--', marker = 'o')\n",
    "    \n",
    "plt.title(\"One Layer vs. Three Layer Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the biggest differences between the 100 node and the 16 node architecture is 100 node architecture plateuas at a much higher validation accuracy while maintaining a similar high training accurracy and corresponding low losses.\n",
    "\n",
    "Other than that, the differences between both the Three Layer Model and the One Layer model both running the 100 node architecture, the Three Layer Model plateaus at a much higher validation accuracy and correspodingly lower loss.\n",
    "\n",
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Evaluate the test accuracy of the model before any training has taken place.  Compare this to the accuracy post-training, and comment on whether or not this is what you'd expect.\n",
    "\n",
    "#### Question attempted with 3 layer model with 100 node architecture as from previous tests, this gave the best results. \n",
    "\n",
    "#### Pretraining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_model = keras.Sequential([\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "pretraining_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "pretraining_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posttraining_model = keras.Sequential([\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "posttraining_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "posttraining_model.fit(x_train, y_train, epochs = 4, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results kind of represent what I expected. The untrained model achieved a accuracy of 50% which is higher than expected but hopefully the histogram of ouputs provides more insight into this. The trained model achieved a much higher accuracy with an accuracy of 87.5% after 4 epochs of training. \n",
    "\n",
    "\n",
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Generate a histogram of the output probabilities.  Explain what this represents. (use 10 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prediction = pretraining_model.predict(x_test)\n",
    "plt.hist(pre_prediction, bins=10)\n",
    "plt.gca().set(title='Pre Training Histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "post_prediction = posttraining_model.predict(x_test)\n",
    "plt.hist(post_prediction, bins=10)\n",
    "plt.gca().set(title='Post Training Histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram did provide more insight. In the untrained model, the results are centered roughly around 0.5, in whihc values below 0.5 were rounded to 0 and values above, to 1. This loosely explains why the results had around a 50% accuracy. \n",
    "\n",
    "After the model was trained, it provided more concrete predictions as to whether it was a 1 or 0.\n",
    "\n",
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Find all the predictions where the model got the answer wrong.  Generate a histogram of the corresponding output probabilities.  Explain what this represents, and comment on whether or not it looks like you'd expect. (Use 10 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_prediction_falses = np.round(pre_prediction)[:, 0]\n",
    "pre_prediction_falses = pre_prediction_falses[pre_prediction_falses != y_test]\n",
    "num_untrained_falses = len(pre_prediction_falses)\n",
    "plt.hist(pre_prediction_falses, bins=10)\n",
    "plt.gca().set(title='Pre Training Wrong Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre training model predicted around 12500 results wrong - 12000 of them were predicted to be 1s but were acutally 0s and around 500 were 0s when they should have been 1s. This matches our expectations of a 50% accuracy as 12500 is 50% of the original dataset. Moreover we noticed the pre-training histogram was skewed to the right, which means that more values were predicted to be ones and correspondingly a larger number were false predictions.\n",
    "\n",
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_prediction_falses = np.round(post_prediction)[:, 0]\n",
    "post_prediction_falses = post_prediction_falses[post_prediction_falses != y_test]\n",
    "num_trained_falses = len(post_prediction_falses)\n",
    "print(len(post_prediction_falses))\n",
    "plt.hist(post_prediction_falses, bins=10)\n",
    "plt.gca().set(title='Pre Training Wrong Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Trained Model predicted a total of 3116 values wrong (around 1100 were predicted to be 0s instead of 1s and around 2.1k were predicted to be 1s instead of 0s). 3116 wrong values results in an error rate of 12.464% which corresponds to a accuracy of 87.54% which matches with our results from the sections before. No unexpected behaviour was seen here.\n",
    "\n",
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Divide the answers from the second histogram by the answers from the first histogram.  Explain what this represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the number of errors by the total number of samples (second_hist/first_hist) gives us the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_untrained = num_untrained_falses/len(pre_prediction)\n",
    "print(\"The untrained model's error rate was {}\".format(error_rate_untrained))\n",
    "\n",
    "error_rate_trained = num_trained_falses/len(post_prediction)\n",
    "print(\"The trained model's error rate was {}\".format(error_rate_trained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4e188544cbef0c7c9b56048d72f4677869155490c54ad310f0307de4b79d413"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
